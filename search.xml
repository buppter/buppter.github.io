<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[数据库索引优化]]></title>
    <url>%2F2019%2F07%2F16%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[对于数据库的优化主要包括三个部分：查询优化、索引优化和字段类型优化，其中，索引优化则是数据库优化的重中之重。一个查询使用索引与不使用索引的差别可能只在100个数量级，而一个好的索引与不好的索引差别可能在1000个数量级，但是一个最优的索引与普通的索引查询效率可能就相差上万甚至更高的数量级。本文主要重点讲解数据库索引的优化。一、 SQL性能下降原因性能下降SQL慢执行时间长等待时间长查询语句写的烂索引失效关联查询太多join（设计缺陷或不得已需求）服务器调优以及各个参数设置（缓冲，线程数等）二、七种Jion三、 索引1. 创建索引12345678# 普通索引ALTER TABLE table_name ADD INDEX index_name (column_list)# 唯一索引ALTER TABLE table_name ADD UNIQUE INDEX index_name (column_lsit)# 主键索引ALTER TABLE table_name ADD PRIMARY KEY (column)2. 查看索引1SHOW INDEX FROM table_name3. 删除索引1234567DROP INDEX [index_name] ON table_name# 或者ALTER TABLE table_name DROP INDEX index_name# eg:删除主键ALTER TABLE table_name DROP PRIMARY KEY四、哪些情况需要建立索引主键自动建立唯一索引频繁作为查询条件的字段应该建立索引查询中与其他表关联的字段，外键关系建立索引单值索引与组合索引的选择：高并发下倾向于组合索引查询中排序的字段，若通过索引去访问将大大提高排序速度查询中统计或分组的段五、哪些情况不要建立索引表记录过少经常增删改的表为了提高查询速度，同时却会降低更新表的速度。因为更新表时，不仅要保存数据，还要更新索引文件。数据重复且分布均匀的表字段，因此应该只为最经常查询和排序的数据列建立索引频繁更新的字段不适合创建索引更新索引，加重了IO负担where条件里用不到的字段不创建索引六、增加索引带来的问题创建索引和维护索引需要耗费时间，并且随着数据量的增加所耗费的时间也会增加索引需要占磁盘空间，除了数据表占数据空间以外，每一个索引还要占一定的空间。如果有大量的索引，索引文件可能比数据文件更快达到最大文件尺寸。当对表中的数据进行增删改是，索引也需要动态的维护，这样就降低了数据的维护速度。七、性能分析使用 EXPLAIN 关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理SQL语句的，从而进行优化1. 具体能干嘛表的读取顺序数据读取操作的操作类型哪些索引可以使用哪些索引被实际使用表之间的引用每张表有多少行被优化器查询2. 具体怎么用1EXPLAIN + SQL语句返回的信息：八、 EXPLAIN 各个名词的解释1. idselect 查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序四种情况id 相同： 执行顺序由上至下id 不同：id 值越大，优先级越高，越先被执行id 有相同也有不同，首先执行 id 值大的语句，id 值相同的，由上至下顺序执行null 表示用来合并结果集，在SQL中使用 UNION 关键字合并结果集就会出现它2. select_type指定所使用的 SELECT 查询类型，主要用于区别普通查询、联合查询、子查询等复杂查询2.1 SIMPLE简单的 SELECT 查询，查询不包含子查询或者UNION2.2 PRIMARY查询中最外层的SELECT（如两表做UNION或者存在子查询的外层的表操作为PRIMARY，内层的操作为UNION）2.3 SUBQUERY在 SELECT 或 WHERE 中包含了子查询中的首个 SELECT (如果有多个子查询存在)2.4 DEPENDENT SUBQUERY子查询中首个 SELECT，但依赖于外层的表（如果有多个子查询存在）重点解释子查询的查询方式依赖于外面的查询结果.用这个例子就是,先进行子查询外部的查询,得到一个结果集,.然后这个结果的每一行在跟select子查询的结果集进行匹配,也就是说,外部结果集的每一行都要关联内部结果集一次2.5 DERIVED在 FROM 列表中包含的子查询被标记为 DERIVED(衍生)，MySQL会递归执行这些子查询，把结果放在临时表里。2.6 UNION若第二个 SELECT 出现在 UNION 之后，则会被标记为UNION；若UNION包含在 FROM 子句的子查询中，外层的 SELECT 将会被标记为 DERIVED2.7 UNIOIN RESULTUNION操作的结果，id值通常为NULL3.table显示这一行的数据是关于哪一张表的4.type表示访问类型，通俗解释就是MySQL查找数据列的方式。下边从最优到最差的顺序分别介绍4.1 system表中只有一条数据. 这个类型是特殊的 const 类型4.2 const表示通过索引一次就找到了数据列，const 用于比较 primary key 或者 unique 索引。因为只匹配一行数据，所以查询速度很快。比如将主键当做 WHERE 条件去查询，MySQL可以将这个查询转换为一个常量。4.3 eq_ref唯一性索引扫描，对于每一个索引键，表中只有一条记录与之匹配。常见于主键或唯一索引扫描。4.4 ref针对于非唯一或非主键索引, 或者是使用了 最左前缀 规则索引的查询，返回匹配某个单独值的所有行。本质上也是一种索引访问，它返回所有匹配某个单独值的行，但是它可能会找到多个符合条件的 行，所以它应该属于查找和扫描的混合体。4.5 range只检索给定范围的行，使用一个索引来选择行。 key 列显示使用了哪个索引。一般是在 WHERE 语句中出现了 between &lt; &gt; in 等的查询。这种范围扫描索引比全表扫描索引要好，因为它只需要开始于索引的某一点，而结束于另一点，不用扫描全部索引。4.6 index表示全索引扫描，index 与 ALL 的区别在于 index 类型只遍历索引树。4.7 ALL全表扫描，没有用到任何的index，效率最差。总结从最好到最差依次是：system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL一般来说，得保证查询至少达到 range 级别，最好能达到 ref5. possible_keys显示可能应用在这张表中的索引，一个或多个。查询涉及的字段若存在索引，则改索引将被列出，但不一定被查询实际用到6. key实际中用到的索引，如果为 NULL 则表示没有用到索引如查询中用到了覆盖索引，则该索引和查询的 SELECT 字段重叠覆盖索引：在本例中：我在 addr 和 email 上建立聚合索引，在查询时也查询的是 addr 和 email 这两个字段，所以刚好和索引匹配了。当发起一个被索引覆盖的查询(也叫作索引覆盖查询)时，在 Extra 列可以看到 Using index 的信息7. key_len表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。在不损失精确性的情况下，长度越短越好。key_len 显示的值为索引字段的最大可能长度，并非实际使用长度，即 key_len 是根据表定义计算而得，不是通过表内检索出的。8. ref显示索引的哪一列被使用了，如果可能的话，是一个常数。常见的值有 const, func, NULL, 具体字段名。当 key 列为 NULL ，即不使用索引时 。如果值是 func，则使用的值是某个函数的结果9. rows根据表统计信息及索引使用情况，大致估算出找到所需的记录所需要读取的行数。简单且重要，数值越大越不好，说明没有用好索引10. Extra该列包含 MySQL 查询的详细信息。10.1 Using filesort (出现这个表示效果不好)说明 MySQL 会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。MySQL 中无法利用索引完成的排序操作称为“文件排序”10.2 Using temporary (出现这个表示效果不好)使用了临时表保存中间结果，MySQL 在对查询结果进行排序是使用临时表。常见于排序 ORDER BY 和分组查询 GROUP BY10.3 Using index (出现这个表示效果好)表示相应的 SELECT 操作中使用了覆盖索引，避免访问了表的数据行，效率不错。如果同时出现 Using where 表示索引被用来执行索引键值的查找如果没有出现 Using where 表示索引用来读取数据而非执行查找动作。10.4 Using where表示使用了 WHERE 过滤10.5 Using join buffer使用了连接缓存10.6 Impossible whereWHERE 子句的值总是 False ， 不能用来获取任何数据列。九、避免索引失效1. 全值匹配对于联合索引，在 WHERE 子查询是尽量使用所有索引列来过滤查询2. 最左前缀原则联合索引下，查询从索引的最左前列开始并且不能跳过索引中间的列3. 不在索引列上做任何操作不要在索引列上进行 计算、函数、（自动或手动）类型转换，否则会导致索引失效而转向全表扫描。4. 范围条件查询会导致右边的索引失效解释：当我们三个索引都使用时， key_len 为 107，在使用前两个索引时， key_len 值为 40此时，我们在 WHERE 子查询过滤条件中使用了范围条件，从而导致索引 addr 失效。5. 尽量使用覆盖索引，减少 SELECT * 的使用6. 使用不等于(!= 或 &lt;&gt;) 会导致索引失效7. is null, is not null 也会导致索引失效8. LIKE 以通配符开头 (‘%字符串’) 会导致索引失效解决办法可以使用以通配符结尾来检索 &#39;字符串%&#39;9. 字符串不加引号会导致索引失效解释第 3 条里说道，不要自动或手动做类型转换。这里 20000 为字符串，当我们在查询时不加引号的话，那么 MySQL 会自动做类型转换，导致索引失效10. 少用 OR，会导致索引失效]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>索引</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[macOS下给VScode安装Golang插件]]></title>
    <url>%2F2019%2F04%2F06%2FmacOS%E4%B8%8B%E7%BB%99VScode%E5%AE%89%E8%A3%85Golang%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[最近学习Golang，IDE选择了VScode，主要原因是VScode轻巧还有丰富的各种插件。但是在配置好环境之后，vscode提示我安装插件，却一直安装失败，在折腾了好久之后终于算是安装成功了，所以记录一下。这里不讲具体的Golang和VScode的具体安装过程，需要的可以百度其他博客的讲解。这里直接讲解如何安装其他插件。切换到GOPATH路径下1cd $GOPATH/src然后在src文件夹下新建两个文件夹以及子文件夹12sudo mkdir -p github.com/golangsudo mkdir -p golang.org/x克隆GitHub上的tools工具包:12cd $GOPATH/src/github.com/golanggit clone https://github.com/golang/tools.git tools再将tools文件夹拷贝到golang.org/x文件夹下:12345# 首先在golang.org/x下新建一个tools的文件夹mkdir %GOPATH/src/golang.org/x/tools# 然后把刚刚下载的tools工具包下的文件都拷贝过去cp -r $GOPATH/src/github.com/golang/tools/ $GOPATH/src/golang.org/x/tools/然后返回到$GOPATH目录下，执行go install命令即可。123456789101112131415161718cd $GOPATHgo install github.com/ramya-rao-a/go-outlinego install github.com/acroca/go-symbolsgo install golang.org/x/tools/cmd/gurugo install golang.org/x/tools/cmd/gorenamego install github.com/josharian/implgo install github.com/rogpeppe/godefgo install github.com/sqs/goreturnsgo install github.com/golang/lint/golintgo install github.com/cweill/gotests/gotestsgo install github.com/ramya-rao-a/go-outlinego install github.com/acroca/go-symbolsgo install golang.org/x/tools/cmd/gurugo install golang.org/x/tools/cmd/gorenamego install github.com/josharian/implgo install github.com/rogpeppe/godefgo install github.com/sqs/goreturnsgo install github.com/cweill/gotests/gotests可能还会提示golint安装失败，是因为golint在tools里不包括，单独下载下来安装就可以了12345cd $GOPATH/src/golang.org/xgit clone https://github.com/golang/lint.git# 返回#GOPATH目录go install golang.org\x\lint\golint至此，所有的插件都安装完成。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python后端开发面试题]]></title>
    <url>%2F2019%2F03%2F27%2FPython%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[整理了自己在Python后台开发求职面试过程中的一些面试题，基本涵盖了Python的基础知识，数据库知识，HTTP协议相关，以及基础的数据结构与算法。也方便自己后续面试的时候回来复习。Python的单例123456"""使用__new__来实现单例"""class Singleton(object): def __new__(cls, *args, **kwargs): if not hasattr(cls, '_instance'): cls._instance = super(Singleton,cls).__new__(cls, *args, **kwargs) return cls._instance123456789101112"""使用装饰器"""def Singleton(func): instance = &#123;&#125; def wrapper(*args, **kwargs): if func not in instance: instance[func] = func(*args, **kwargs) return instance[func] return wrapper @Singletonclass Myclass: pass123456789101112"""使用模块"""# singleton.pyclass Singleton(): def foo(self): passsingleton = Singleton()#将上边的代码保存为一个模块，然后可以在别的模块中引用from singleton import singletonsingleton.foo()Python的垃圾回收机制Python中的垃圾回收机制主要以引用计数为主，标记-清除和分代回收为辅。引用计数的缺点：1. 维护引用计数消耗资源。2. 循环引用问题标记-清除：分为两个阶段，第一阶段是标记阶段，把所有的活动对象打上标记；第二阶段把没有被标记的对象进行回收。 从根对象（root object）出发，沿着有向边遍历对象，可达的（reachable）对象标记为活动对象，不可达的对象就是要被清除的非活动对象。在下图中，我们把小黑圈视为全局变量，也就是把它作为root object，从小黑圈出发，对象1可直达，那么它将被标记，对象2、3可间接到达也会被标记， 而4和5不可达，那么1、2、3就是活动对象，4和5是非活动对象会被GC回收。缺点就是清除非活动对象前必须扫描整个堆内存。分代回收：Python将内存根据生存时间划分为不同的集合，每个集合称为一个代。一共有三代，分别为年轻代（第0代），中年代（第1代），老年代（第2代）， 新创建的对象都被分在第0代，当第0代链表数达到上限，Python的垃圾回收机制就会被触发，把那些可以被回收的对象回收掉，不会被回收的就被移到第1代，以此类推。第2代中的对象就是存活时间最长的对象。Python的生成器、迭代器生成器节约内存，需要的时候才产生结果，而不是立即产生。Python中有两种创建生成器的方式：第一种将列表推导式的方括号[]改成圆括号()；第二种是生成器函数，带有yield关键字的函数，使用yield返回值而不是return。12345678910111213"""生成器表达式"""ge = (i**2 for i in range(4))print(ge)for i in ge: print(i) """结果"""&lt;generator object &lt;genexpr&gt; at 0x02D5FE70&gt;01491234567891011121314151617181920212223"""生成器函数使用生成器函数实现斐波那切数列"""def fib(n): a, b, count = 0, 1, 0 while count &lt; n: yield b a, b = b, a + b count += 1 return "Done"print(fib(5)) for i in fib(5): print(i) """输出结果"""&lt;generator object fib at 0x0376FE70&gt;11235生成器有__next__()和send()两个方法。f.__next__()和next(f)作用都是一样的，打印生成器的下一个结果。send()主要用来向生成器中导入参数。在调用send()方法前需要至少调用一次next()或者有__next__()方法。也可以使用send(None)来实现对生成器函数的预激12345678910111213141516171819202122def test(): value = 0 while True: temp = yield value if temp == 'e': break value = "got %s" % temp t = test()print(t.__next__()) # 或者print(next(t)) 再或者 print(t.send(None))t.send("hhh")t.send("aaa")t.send("e") """运行结果"""0get hhhget aaaTraceback (most recent call last): File "test.py", line 14, in &lt;module&gt; print(t.send("e"))StopIteration注意：需要注意的一点是在使用yield from的时候会自动预激Python的多线程、多进程、协程Python的作用域yield 和 yield from具体讲解Python中的锁具体讲解Python的闭包，装饰器__init__ 和 __new__*args`和 **kwages数据库中的锁乐观锁和悲观锁数据库中的join具体讲解MySQL的存储引擎InnoDB和MyISAM数据库的事务具体讲解数据库的索引分为单行索引和组合索引。其中单行索引又分为普通索引、主键索引（不允许为空，唯一）和 唯一索引（可以为空，但唯一）具体讲解Redis的数据持久化（AOF和RDB)HTTP 1.0、HTTP 1.1和HTTP 2.0的区别具体讲解WebSocketWebSocket 是 HTML5 开始提供的一种在单个 TCP 连接上进行全双工通讯的协议。WebSocket 使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在 WebSocket API 中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。HTTP的请求报文和响应报文一次完整的HTTP请求过程域名解析首先搜索浏览器自身的DNS缓存如果浏览器自身缓存没有，就搜索系统自身的缓存如果系统自身的缓存没有，就搜索host文件如果host文件没有，则向本地配置的DNS服务器发起域名解析请求（本地域名服务器）如果本地域名服务器依旧没有找到，就会有递归和迭代两种方法解析迭代：a. 本地域名服务器想根域名服务器发起请求b. 根域名服务器返回给本地域名服务器我们该向哪个顶级域名去请求c. 顶级域名服务器想权限域名服务器发请求d. 返回本地域名服务器IP地址e5. 返回给系统内核，最后返回给浏览器递归：a. 本地域名服务器向根域名服务器发请求b. 之后根域名服务器向顶级域名服务器去找c. 顶级域名服务器返回给根域名服务器d. 根域名服务器返回给本地服务器e. 返回给系统，最后返回给浏览器TCP连接发起HTTP请求服务器响应HTTP请求，同时浏览器得到HTML代码浏览器解析HTML代码，并请求HTML代码中的资源浏览器将页面渲染给用户GET和POST的区别GET是将请求的数据和header一并发送给服务器，只发送一次TCP包POST是先发送header给服务器，然后服务器返回100，再将数据发送给服务器，发送了两次TCP包TCP三次握手和四次挥手TIME_WAIT的原因发生在主动请求关闭的一方TCP和UDP的区别TCP面向连接，UDP无连接TCP提供可靠服务，UDP不保证可靠交付UDP有较好的实时性TCP只支持点到点通信，UDP支持一对一，一对多，多对一和多对多通信TCP对系统资源要求较多，UDP对系统资源要求较少TCP数据容易发生粘包TCP的粘包发送方引起的粘包是由TCP协议本身造成的，TCP为提高传输效率，发送方往往要收集到足够多的数据后才发送一包数据。若连续几次发送的数据都很少，通常TCP会根据优化算法把这些数据合成一包后一次发送出去，这样接收方就收到了粘包数据。接收方引起的粘包是由于接收方用户进程不及时接收数据，从而导致粘包现象。这是因为接收方先把收到的数据放在系统接收缓冲区，用户进程从该缓冲区取数据，若下一包数据到达时前一包数据尚未被用户进程取走，则下一包数据放到系统接收缓冲区时就接到前一包数据之后，而用户进程根据预先设定的缓冲区大小从系统接收缓冲区取数据，这样就一次取到了多包数据。解决办法就是封包、拆包。给一段数据加上包头,这样一来数据包就分为包头和包体两部分内容了(以后讲过滤非法包时封包会加入”包尾”内容)。包头其实上是个大小固定的结构体，其中有个结构体成员变量表示包体的长度，这是个很重要的变量，其他的结构体成员可根据需要自己定义。根据包头长度固定以及包头中含有包体长度的变量就能正确的拆分出一个完整的数据包。select、poll和epoll的区别select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的。select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。缺点：select最大的缺陷就是单个进程所打开的FD是有一定限制的，它由FD_SETSIZE设置，默认值是1024对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低。需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。 poll没有最大连接数的限制，因为它是采用链表来存储的缺点：大量的fd的数组被整体复制于用户态和内核地址空间之间，对于系统的开销比较大poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。注意：从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。优点：没有最大并发连接的限制效率提升，不是轮询的方式，不会随着FD数目的增加效率下降内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符， 一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。 (此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在）综上，在选择select，poll，epoll时要根据具体的使用场合以及这三种方式的自身特点：1、表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。2、select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善。几种排序具体讲解链表栈，队列完全二叉树，平衡二叉树，红黑树，B树，B+树，二叉搜索树平衡二叉树红黑树B树，B+树进程间的通信方式消息队列，信号量，管道，共享内存，Socket具体讲解进程程的状态就绪，运行，阻塞具体讲解Docker具体讲解网络七层协议，五层协议，TCP/IP四层协议七层：物理层，数据链路层，网络层，传输层，会话层，表示层，应用层五层：物理层，数据链路层，网络层，传输层，应用层四层：网络接口层，网络层，传输层，应用层具体讲解RESRful使用HTTPSAPI域名和版本号HTTP动词，GET、DELETE、PUT、POST过滤，排序，搜索，分页状态码和文字说明文档具体讲解MVVC多版本并发控制具体讲解Ping用的什么协议ICMP 网络控制消息协议堆排序堆(heap): 父节点的值大于子节点的值的完全二叉树1234567891011121314151617181920212223242526def heapify(alist, n, i): if i &gt;= n: return c1 = 2 * i + 1 c2 = 2 * i + 2 max_index = i if c1 &lt; n and alist[c1] &gt; alist[max_index]: max_index = c1 if c2 &lt; n and alist[c2] &gt; alist[max_index]: max_index = c2 if max_index != i: alist[i], alist[max_index] = alist[max_index], alist[i] heapify(alist, n, max_index)def build_heap(alist, n): last_node = n - 1 last_node_parent = n//2 -1 for i in range(last_node_parent, -1, -1): heapify(alist, n, i)def heap_sort(alist, n): build_heap(alist, n) for i in range(n-1, -1, -1): alist[i], alist[0] = alist[0], alist[i] heapify(alist, i, 0)]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>HTTP</tag>
        <tag>MySQL</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLAchemy中处理两张表之间存在多个外键的情况]]></title>
    <url>%2F2019%2F01%2F24%2FSQLAchemy%E4%B8%AD%E5%A4%84%E7%90%86%E4%B8%A4%E5%BC%A0%E8%A1%A8%E4%B9%8B%E9%97%B4%E5%AD%98%E5%9C%A8%E5%A4%9A%E4%B8%AA%E5%A4%96%E9%94%AE%E7%9A%84%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[在Flask的开发中，我们势必会遇到两张表之间存在多个外键的情况。例如，现在有两张表，一张表是User，另一张表是Article。一篇文章的作者author_id可以设置外键关联User表，同时文章的审稿人reviewer_id也可以设置外键关联User表。当我们以SQLAchemy多对一(many to one)的设计方法来添加relationship关系映射时，程序会抛出一个AmbiguousForeignKeysError错误，这篇文章我们就来解决这个问题。出现Error的代码写法先来看以SQLAchemy多对一的常规设计方法处理这个问题时我的代码写法。12345678910111213141516171819from flask_sqlalchemy import SQLAlchemydb = SQLAlchemy()class User(db.Model): __tablename__ = 'users' id = db.Column(db.Integer, primary_key=True) email = db.Column(db.String(64), nullable=False, unique=True) name = db.Column(db.String(32), nullable=False) ... class Article(db.Model): __tablename__ = 'articles' id = db.Column(db.Integer, primary_key=True) title = db.Column(db.String(64), nullable=False) author_id = db.Column(db.Integer, db.ForeignKey("users.id")) reviewer_id = db.Column(db.Integer, db.ForeignKey("users.id")) author = db.relationship('User', backref='articles') reviewer = db.relationship('User', backref='review_articles')看起来程序的设计应该是没问题，可运行的结果真的跟我们预想的一样吗？当我们运行代码后，程序抛出了一个错误：12345sqlalchemy.exc.AmbiguousForeignKeysError: Could not determine join condition between parent/child tables on relationship Article.author - there are multiple foreign key paths linking the tables. Specify the &apos;foreign_keys&apos; argument, providing a list of those columns which should be counted as containing a foreign key reference to the parent table.可以看到SQLAchemy提示无法确定Article.author的父子表之间的关联，原因在于两张表之间存在多个外键。需要我们指定foreign_keys参数，提供一个包含关联了父表（即User表）外键的字段列表（list)解决办法查询了很多博客资料后这个问题依旧没有得到解决，只好去阅读SQLAchemy的官方文档，在SQLAchemy ORM &gt; Relationship Configuation &gt; Configuring how Relationship Joins下有关于Handling Multiple Join Paths的介绍。文档中说，在遇到两表之间存在多外键关联时，需要给relationship()指定foreign_keys参数。需要对我们的代码进行修改，添加foreign_keys参数，所以将代码修改为：12345678910111213141516171819202122232425from flask_sqlalchemy import SQLAlchemydb = SQLAlchemy()class User(db.Model): __tablename__ = 'users' id = db.Column(db.Integer, primary_key=True) email = db.Column(db.String(64), nullable=False, unique=True) name = db.Column(db.String(32), nullable=False) ... def __repr__(self): return '&lt;User id=&#123;0&#125;, name=&#123;1&#125;&gt;'.format(self.id, self.name) class Article(db.Model): __tablename__ = 'articles' id = db.Column(db.Integer, primary_key=True) title = db.Column(db.String(64), nullable=False) author_id = db.Column(db.Integer, db.ForeignKey("users.id")) reviewer_id = db.Column(db.Integer, db.ForeignKey("users.id")) author = db.relationship('User', backref='articles', foreign_keys=[author_id]) reviewer = db.relationship('User', backref='review_articles', foreign_keys=[reviewer_id]) def __repr__(self): return '&lt;Article id=&#123;0&#125;, title=&#123;1&#125;&gt;'.format(self.id, self.title)同时，在指定foreign_keys时，我们也可以使用字符串来指定。但如果使用列表，则列表必须是字符串的一部分。1author = db.relationship('User', backref='articles', foreign_keys="[author_id]")在我们这个具体的例子中，不需要列表，所以可以写成：1author = db.relationship('User', backref='articles', foreign_keys="author_id")测试在修改过后，我们运行程序，测试一下代码我们先给User表添加两条数据1234&gt;&gt;&gt; zhangsan = User(email=&apos;zhangsan@123.com&apos;, name=&apos;张三&apos;)&gt;&gt;&gt; lisi = User(emaill=&apos;lisi@123.com&apos;, name=&apos;李四&apos;)&gt;&gt;&gt; db.session.add_all([zhangsan,lisi])&gt;&gt;&gt; db.session.commit()接着给Article表添加一条记录，指定Author为张三(users.id=1)，Reviewer为李四(users.id=2)123456&gt;&gt;&gt; article = Article()&gt;&gt;&gt; article.title = &quot;Test&quot;&gt;&gt;&gt; article.author_id = 1&gt;&gt;&gt; article.reviewer_id = 2&gt;&gt;&gt; db.session.add(article)&gt;&gt;&gt; db.session.commit()我们来做查询操作1234567&gt;&gt;&gt; article = Article.query.get(1)&gt;&gt;&gt; article&lt;Article id=1, title=Test&gt;&gt;&gt;&gt; article.author&lt;User id=1, name=张三&gt;&gt;&gt;&gt; article.reviewer&lt;User id=2, name=李四&gt;可以看到我们可以正确的查询到article.author和article.reviewer，关于SQLAchemy中处理两张表之间存在多个外键的情况这个问题我们已经解决。扩展在relationship()中我们添加了backref参数来对关系提供反向引用，这样更加方便了我们的查询操作。示例：1234567&gt;&gt;&gt; zhangsan = User.query.filter_by(name=&apos;张三&apos;).first()&gt;&gt;&gt; zhangsan&lt;User id=1, name=张三&gt;&gt;&gt;&gt; zhangsan.articles[&lt;Article id=1, title=Test&gt;]&gt;&gt;&gt; zhangsan.review_articles[]因为我们给artice.author添加了articles的反向引用，给article.reviewer添加了review_articles的反向引用。所以对于User 张三来说，他是article Test的Author，可以通过article.author来查询得到张三。也可以通过zhangsan.articles反向查询得到Test这篇文章。同时，因为张三不是任何一篇文章的reviewer，所以通过zhangsan.review_articles查询到结果为空列表。同样的，我们来看李四的查询操作：1234567&gt;&gt;&gt; lisi = User.query.filter_by(name=&apos;李四&apos;).first()&gt;&gt;&gt; lisi&lt;User id=2, name=李四&gt;&gt;&gt;&gt; lisi.articles[]&gt;&gt;&gt; lisi.review_articles[&lt;Article id=1, title=Test&gt;]结果其实跟张三的查询是类似的，只是两人的角色author和reviewer不同，这里不再啰嗦。]]></content>
      <categories>
        <category>Flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Flask-SQLAchemy</tag>
        <tag>SQLAchemy</tag>
      </tags>
  </entry>
</search>
