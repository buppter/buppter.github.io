<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python后端开发面试题]]></title>
    <url>%2F2019%2F03%2F27%2FPython%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[整理了自己在Python后台开发求职面试过程中的一些面试题，基本涵盖了Python的基础知识，数据库知识，HTTP协议相关，以及基础的数据结构与算法。也方便自己后续面试的时候回来复习。Python的单例123456"""使用__new__来实现单例"""class Singleton(object): def __new__(cls, *args, **kwargs): if not hasattr(cls, '_instance'): cls._instance = super(Singleton,cls).__new__(cls, *args, **kwargs) return cls._instance123456789101112"""使用装饰器"""def Singleton(func): instance = &#123;&#125; def wrapper(*args, **kwargs): if func not in instance: instance[func] = func(*args, **kwargs) return instance[func] return wrapper @Singletonclass Myclass: pass123456789101112"""使用模块"""# singleton.pyclass Singleton(): def foo(self): passsingleton = Singleton()#将上边的代码保存为一个模块，然后可以在别的模块中引用from singleton import singletonsingleton.foo()Python的垃圾回收机制Python中的垃圾回收机制主要以引用计数为主，标记-清除和分代回收为辅。引用计数的缺点：1. 维护引用计数消耗资源。2. 循环引用问题标记-清除：分为两个阶段，第一阶段是标记阶段，把所有的活动对象打上标记；第二阶段把没有被标记的对象进行回收。 从根对象（root object）出发，沿着有向边遍历对象，可达的（reachable）对象标记为活动对象，不可达的对象就是要被清除的非活动对象。在下图中，我们把小黑圈视为全局变量，也就是把它作为root object，从小黑圈出发，对象1可直达，那么它将被标记，对象2、3可间接到达也会被标记， 而4和5不可达，那么1、2、3就是活动对象，4和5是非活动对象会被GC回收。缺点就是清除非活动对象前必须扫描整个堆内存。分代回收：Python将内存根据生存时间划分为不同的集合，每个集合称为一个代。一共有三代，分别为年轻代（第0代），中年代（第1代），老年代（第2代）， 新创建的对象都被分在第0代，当第0代链表数达到上限，Python的垃圾回收机制就会被触发，把那些可以被回收的对象回收掉，不会被回收的就被移到第1代，以此类推。第2代中的对象就是存活时间最长的对象。Python的生成器、迭代器生成器节约内存，需要的时候才产生结果，而不是立即产生。Python中有两种创建生成器的方式：第一种将列表推导式的方括号[]改成圆括号()；第二种是生成器函数，带有yield关键字的函数，使用yield返回值而不是return。12345678910111213"""生成器表达式"""ge = (i**2 for i in range(4))print(ge)for i in ge: print(i) """结果"""&lt;generator object &lt;genexpr&gt; at 0x02D5FE70&gt;01491234567891011121314151617181920212223"""生成器函数使用生成器函数实现斐波那切数列"""def fib(n): a, b, count = 0, 1, 0 while count &lt; n: yield b a, b = b, a + b count += 1 return "Done"print(fib(5)) for i in fib(5): print(i) """输出结果"""&lt;generator object fib at 0x0376FE70&gt;11235生成器有__next__()和send()两个方法。f.__next__()和next(f)作用都是一样的，打印生成器的下一个结果。send()主要用来向生成器中导入参数。在调用send()方法前需要至少调用一次next()或者有__next__()方法。也可以使用send(None)来实现对生成器函数的预激12345678910111213141516171819202122def test(): value = 0 while True: temp = yield value if temp == 'e': break value = "got %s" % temp t = test()print(t.__next__()) # 或者print(next(t)) 再或者 print(t.send(None))t.send("hhh")t.send("aaa")t.send("e") """运行结果"""0get hhhget aaaTraceback (most recent call last): File "test.py", line 14, in &lt;module&gt; print(t.send("e"))StopIteration注意：需要注意的一点是在使用yield from的时候会自动预激Python的多线程、多进程、协程Python的作用域yield 和 yield from具体讲解Python中的锁具体讲解Python的闭包，装饰器__init__ 和 __new__*args`和 **kwages数据库中的锁乐观锁和悲观锁数据库中的join具体讲解MySQL的存储引擎InnoDB和MyISAM数据库的事务具体讲解数据库的索引分为单行索引和组合索引。其中单行索引又分为普通索引、主键索引（不允许为空，唯一）和 唯一索引（可以为空，但唯一）具体讲解Redis的数据持久化（AOF和RDB)HTTP 1.0、HTTP 1.1和HTTP 2.0的区别具体讲解WebSocketWebSocket 是 HTML5 开始提供的一种在单个 TCP 连接上进行全双工通讯的协议。WebSocket 使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在 WebSocket API 中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。HTTP的请求报文和响应报文一次完整的HTTP请求过程域名解析首先搜索浏览器自身的DNS缓存如果浏览器自身缓存没有，就搜索系统自身的缓存如果系统自身的缓存没有，就搜索host文件如果host文件没有，则向本地配置的DNS服务器发起域名解析请求（本地域名服务器）如果本地域名服务器依旧没有找到，就会有递归和迭代两种方法解析迭代：a. 本地域名服务器想根域名服务器发起请求b. 根域名服务器返回给本地域名服务器我们该向哪个顶级域名去请求c. 顶级域名服务器想权限域名服务器发请求d. 返回本地域名服务器IP地址e5. 返回给系统内核，最后返回给浏览器递归：a. 本地域名服务器向根域名服务器发请求b. 之后根域名服务器向顶级域名服务器去找c. 顶级域名服务器返回给根域名服务器d. 根域名服务器返回给本地服务器e. 返回给系统，最后返回给浏览器TCP连接发起HTTP请求服务器响应HTTP请求，同时浏览器得到HTML代码浏览器解析HTML代码，并请求HTML代码中的资源浏览器将页面渲染给用户GET和POST的区别GET是将请求的数据和header一并发送给服务器，只发送一次TCP包POST是先发送header给服务器，然后服务器返回100，再将数据发送给服务器，发送了两次TCP包TCP三次握手和四次挥手TIME_WAIT的原因发生在主动请求关闭的一方TCP和UDP的区别TCP面向连接，UDP无连接TCP提供可靠服务，UDP不保证可靠交付UDP有较好的实时性TCP只支持点到点通信，UDP支持一对一，一对多，多对一和多对多通信TCP对系统资源要求较多，UDP对系统资源要求较少TCP数据容易发生粘包TCP的粘包发送方引起的粘包是由TCP协议本身造成的，TCP为提高传输效率，发送方往往要收集到足够多的数据后才发送一包数据。若连续几次发送的数据都很少，通常TCP会根据优化算法把这些数据合成一包后一次发送出去，这样接收方就收到了粘包数据。接收方引起的粘包是由于接收方用户进程不及时接收数据，从而导致粘包现象。这是因为接收方先把收到的数据放在系统接收缓冲区，用户进程从该缓冲区取数据，若下一包数据到达时前一包数据尚未被用户进程取走，则下一包数据放到系统接收缓冲区时就接到前一包数据之后，而用户进程根据预先设定的缓冲区大小从系统接收缓冲区取数据，这样就一次取到了多包数据。解决办法就是封包、拆包。给一段数据加上包头,这样一来数据包就分为包头和包体两部分内容了(以后讲过滤非法包时封包会加入”包尾”内容)。包头其实上是个大小固定的结构体，其中有个结构体成员变量表示包体的长度，这是个很重要的变量，其他的结构体成员可根据需要自己定义。根据包头长度固定以及包头中含有包体长度的变量就能正确的拆分出一个完整的数据包。select、poll和epoll的区别select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的。select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。缺点：1. select最大的缺陷就是单个进程所打开的FD是有一定限制的，它由FD_SETSIZE设置，默认值是1024 2. 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低。 3. 需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。 poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。 poll没有最大连接数的限制，因为它是采用链表来存储的缺点：1. 大量的fd的数组被整体复制于用户态和内核地址空间之间，对于系统的开销比较大 2. poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。 注意：从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。优点：1. 没有最大并发连接的限制 2. 效率提升，不是轮询的方式，不会随着FD数目的增加效率下降 3. 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 在select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符， 一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait()时便得到通知。 (此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在）综上，在选择select，poll，epoll时要根据具体的使用场合以及这三种方式的自身特点：1、表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。2、select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善。几种排序具体讲解链表栈，队列完全二叉树，平衡二叉树，红黑树，B树，B+树，二叉搜索树平衡二叉树红黑树B树，B+树进程间的通信方式消息队列，信号量，管道，共享内存，Socket具体讲解进程程的状态就绪，运行，阻塞具体讲解Docker具体讲解网络七层协议，五层协议，TCP/IP四层协议七层：物理层，数据链路层，网络层，传输层，会话层，表示层，应用层五层：物理层，数据链路层，网络层，传输层，应用层四层：网络接口层，网络层，传输层，应用层具体讲解RESRful使用HTTPSAPI域名和版本号HTTP动词，GET、DELETE、PUT、POST过滤，排序，搜索，分页状态码和文字说明文档具体讲解MVVC多版本并发控制具体讲解Ping用的什么协议ICMP 网络控制消息协议堆排序堆(heap): 父节点的值大于子节点的值的完全二叉树1234567891011121314151617181920212223242526def heapify(alist, n, i): if i &gt;= n: return c1 = 2 * i + 1 c2 = 2 * i + 2 max_index = i if c1 &lt; n and alist[c1] &gt; alist[max_index]: max_index = c1 if c2 &lt; n and alist[c2] &gt; alist[max_index]: max_index = c2 if max_index != i: alist[i], alist[max_index] = alist[max_index], alist[i] heapify(alist, n, max_index)def build_heap(alist, n): last_node = n - 1 last_node_parent = n//2 -1 for i in range(last_node_parent, -1, -1): heapify(alist, n, i)def heap_sort(alist, n): build_heap(alist, n) for i in range(n-1, -1, -1): alist[i], alist[0] = alist[0], alist[i] heapify(alist, i, 0)]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>HTTP</tag>
        <tag>MySQL</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQLAchemy中处理两张表之间存在多个外键的情况]]></title>
    <url>%2F2019%2F01%2F24%2FSQLAchemy%E4%B8%AD%E5%A4%84%E7%90%86%E4%B8%A4%E5%BC%A0%E8%A1%A8%E4%B9%8B%E9%97%B4%E5%AD%98%E5%9C%A8%E5%A4%9A%E4%B8%AA%E5%A4%96%E9%94%AE%E7%9A%84%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[在Flask的开发中，我们势必会遇到两张表之间存在多个外键的情况。例如，现在有两张表，一张表是User，另一张表是Article。一篇文章的作者author_id可以设置外键关联User表，同时文章的审稿人reviewer_id也可以设置外键关联User表。当我们以SQLAchemy多对一(many to one)的设计方法来添加relationship关系映射时，程序会抛出一个AmbiguousForeignKeysError错误，这篇文章我们就来解决这个问题。出现Error的代码写法先来看以SQLAchemy多对一的常规设计方法处理这个问题时我的代码写法。12345678910111213141516171819from flask_sqlalchemy import SQLAlchemydb = SQLAlchemy()class User(db.Model): __tablename__ = 'users' id = db.Column(db.Integer, primary_key=True) email = db.Column(db.String(64), nullable=False, unique=True) name = db.Column(db.String(32), nullable=False) ... class Article(db.Model): __tablename__ = 'articles' id = db.Column(db.Integer, primary_key=True) title = db.Column(db.String(64), nullable=False) author_id = db.Column(db.Integer, db.ForeignKey("users.id")) reviewer_id = db.Column(db.Integer, db.ForeignKey("users.id")) author = db.relationship('User', backref='articles') reviewer = db.relationship('User', backref='review_articles')看起来程序的设计应该是没问题，可运行的结果真的跟我们预想的一样吗？当我们运行代码后，程序抛出了一个错误：12345sqlalchemy.exc.AmbiguousForeignKeysError: Could not determine join condition between parent/child tables on relationship Article.author - there are multiple foreign key paths linking the tables. Specify the &apos;foreign_keys&apos; argument, providing a list of those columns which should be counted as containing a foreign key reference to the parent table.可以看到SQLAchemy提示无法确定Article.author的父子表之间的关联，原因在于两张表之间存在多个外键。需要我们指定foreign_keys参数，提供一个包含关联了父表（即User表）外键的字段列表（list)解决办法查询了很多博客资料后这个问题依旧没有得到解决，只好去阅读SQLAchemy的官方文档，在SQLAchemy ORM &gt; Relationship Configuation &gt; Configuring how Relationship Joins下有关于Handling Multiple Join Paths的介绍。文档中说，在遇到两表之间存在多外键关联时，需要给relationship()指定foreign_keys参数。需要对我们的代码进行修改，添加foreign_keys参数，所以将代码修改为：12345678910111213141516171819202122232425from flask_sqlalchemy import SQLAlchemydb = SQLAlchemy()class User(db.Model): __tablename__ = 'users' id = db.Column(db.Integer, primary_key=True) email = db.Column(db.String(64), nullable=False, unique=True) name = db.Column(db.String(32), nullable=False) ... def __repr__(self): return '&lt;User id=&#123;0&#125;, name=&#123;1&#125;&gt;'.format(self.id, self.name) class Article(db.Model): __tablename__ = 'articles' id = db.Column(db.Integer, primary_key=True) title = db.Column(db.String(64), nullable=False) author_id = db.Column(db.Integer, db.ForeignKey("users.id")) reviewer_id = db.Column(db.Integer, db.ForeignKey("users.id")) author = db.relationship('User', backref='articles', foreign_keys=[author_id]) reviewer = db.relationship('User', backref='review_articles', foreign_keys=[reviewer_id]) def __repr__(self): return '&lt;Article id=&#123;0&#125;, title=&#123;1&#125;&gt;'.format(self.id, self.title)同时，在指定foreign_keys时，我们也可以使用字符串来指定。但如果使用列表，则列表必须是字符串的一部分。1author = db.relationship('User', backref='articles', foreign_keys="[author_id]")在我们这个具体的例子中，不需要列表，所以可以写成：1author = db.relationship('User', backref='articles', foreign_keys="author_id")测试在修改过后，我们运行程序，测试一下代码我们先给User表添加两条数据1234&gt;&gt;&gt; zhangsan = User(email=&apos;zhangsan@123.com&apos;, name=&apos;张三&apos;)&gt;&gt;&gt; lisi = User(emaill=&apos;lisi@123.com&apos;, name=&apos;李四&apos;)&gt;&gt;&gt; db.session.add_all([zhangsan,lisi])&gt;&gt;&gt; db.session.commit()接着给Article表添加一条记录，指定Author为张三(users.id=1)，Reviewer为李四(users.id=2)123456&gt;&gt;&gt; article = Article()&gt;&gt;&gt; article.title = &quot;Test&quot;&gt;&gt;&gt; article.author_id = 1&gt;&gt;&gt; article.reviewer_id = 2&gt;&gt;&gt; db.session.add(article)&gt;&gt;&gt; db.session.commit()我们来做查询操作1234567&gt;&gt;&gt; article = Article.query.get(1)&gt;&gt;&gt; article&lt;Article id=1, title=Test&gt;&gt;&gt;&gt; article.author&lt;User id=1, name=张三&gt;&gt;&gt;&gt; article.reviewer&lt;User id=2, name=李四&gt;可以看到我们可以正确的查询到article.author和article.reviewer，关于SQLAchemy中处理两张表之间存在多个外键的情况这个问题我们已经解决。扩展在relationship()中我们添加了backref参数来对关系提供反向引用，这样更加方便了我们的查询操作。示例：1234567&gt;&gt;&gt; zhangsan = User.query.filter_by(name=&apos;张三&apos;).first()&gt;&gt;&gt; zhangsan&lt;User id=1, name=张三&gt;&gt;&gt;&gt; zhangsan.articles[&lt;Article id=1, title=Test&gt;]&gt;&gt;&gt; zhangsan.review_articles[]因为我们给artice.author添加了articles的反向引用，给article.reviewer添加了review_articles的反向引用。所以对于User 张三来说，他是article Test的Author，可以通过article.author来查询得到张三。也可以通过zhangsan.articles反向查询得到Test这篇文章。同时，因为张三不是任何一篇文章的reviewer，所以通过zhangsan.review_articles查询到结果为空列表。同样的，我们来看李四的查询操作：1234567&gt;&gt;&gt; lisi = User.query.filter_by(name=&apos;李四&apos;).first()&gt;&gt;&gt; lisi&lt;User id=2, name=李四&gt;&gt;&gt;&gt; lisi.articles[]&gt;&gt;&gt; lisi.review_articles[&lt;Article id=1, title=Test&gt;]结果其实跟张三的查询是类似的，只是两人的角色author和reviewer不同，这里不再啰嗦。]]></content>
      <categories>
        <category>Flask</category>
      </categories>
      <tags>
        <tag>Flask</tag>
        <tag>Flask-SQLAchemy</tag>
        <tag>SQLAchemy</tag>
      </tags>
  </entry>
</search>
